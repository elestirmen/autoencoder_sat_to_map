"""
BirleÅŸik AutoEncoder EÄŸitim Scripti
===================================
Bu script, tÃ¼m autoencoder varyasyonlarÄ±nÄ± tek bir dosyada birleÅŸtirir.
TÃ¼m parametreler CONFIG bÃ¶lÃ¼mÃ¼nden yÃ¶netilebilir.

KullanÄ±m:
    python autoencoder_unified.py

Desteklenen Modlar:
    - grayscale: Gri tonlamalÄ± gÃ¶rÃ¼ntÃ¼ler (1 kanal)
    - rgb: Renkli gÃ¶rÃ¼ntÃ¼ler (3 kanal)
    - grayscale_with_equalize: Gri + Histogram eÅŸitleme
"""

import os
import cv2
import numpy as np
import datetime
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import (
    Conv2D, Conv2DTranspose, Input, UpSampling2D, 
    MaxPooling2D, Dropout, BatchNormalization
)
from tensorflow.keras import regularizers
from tensorflow.keras import backend as K

# tensorflow_addons sadece histogram eÅŸitleme iÃ§in gerekli
try:
    import tensorflow_addons as tfa
    TFA_AVAILABLE = True
except ImportError:
    TFA_AVAILABLE = False
    print("UYARI: tensorflow_addons yÃ¼klÃ¼ deÄŸil. Histogram eÅŸitleme devre dÄ±ÅŸÄ±.")


# ==============================================================================
#                              CONFIG BÃ–LÃœMÃœ
# ==============================================================================

class Config:
    """TÃ¼m eÄŸitim parametrelerini buradan yÃ¶netin."""
    
    # ------------------------------ VERÄ° AYARLARI -----------------------------
    # Veri dizini yolu
    DATA_DIR = "maps_zoom_level_19\sonuclar_19"
    
    # Renk modu: "grayscale", "rgb", "grayscale_with_equalize"
    COLOR_MODE = "rgb"
    
    # EÄŸitim/DoÄŸrulama oranÄ± (0.0 - 1.0 arasÄ±, eÄŸitim iÃ§in kullanÄ±lacak oran)
    TRAIN_SPLIT = 0.9
    
    # Random seed (tekrarlanabilirlik iÃ§in)
    RANDOM_SEED = 42
    
    # ------------------------------ MODEL AYARLARI ----------------------------
    # GÃ¶rÃ¼ntÃ¼ boyutu (geniÅŸlik ve yÃ¼kseklik eÅŸit olmalÄ±)
    IMAGE_SIZE = 544
    
    # Dinamik giriÅŸ boyutu (inference iÃ§in)
    # True: Model herhangi bir boyutta gÃ¶rÃ¼ntÃ¼ kabul eder (inference'da)
    # False: Sadece IMAGE_SIZE boyutunda gÃ¶rÃ¼ntÃ¼ kabul eder
    DYNAMIC_INPUT_FOR_INFERENCE = True
    
    # Multi-scale eÄŸitim (data augmentation)
    # True: Her batch farklÄ± boyutlarda olabilir (daha robust model)
    # False: TÃ¼m gÃ¶rÃ¼ntÃ¼ler IMAGE_SIZE boyutuna resize edilir
    MULTI_SCALE_TRAINING = False
    
    # Multi-scale iÃ§in boyut listesi (MULTI_SCALE_TRAINING=True ise kullanÄ±lÄ±r)
    MULTI_SCALE_SIZES = [256, 384, 448, 512, 544]
    
    # Model mimarisi seÃ§imi:
    # "autoencoder", "autoencoder_backup", "upsampled", "advanced", 
    # "gpt", "gpt_no_reg", "deneysel", "classic"
    MODEL_TYPE = "advanced"
    
    # Ã–nceden eÄŸitilmiÅŸ model yÃ¼kle (None = sÄ±fÄ±rdan baÅŸla)
    PRETRAINED_MODEL = None  # Ã–rn: "son_model.h5" veya None
    
    # Aktivasyon fonksiyonu: "sigmoid", "relu", "elu", "tanh"
    ACTIVATION_FUNC = "sigmoid"
    
    # Filtre sayÄ±sÄ± (baÅŸlangÄ±Ã§ filtre sayÄ±sÄ±)
    FILTER_COUNT = 32
    
    # Kernel boyutu
    KERNEL_SIZE = (3, 3)
    
    # Stride deÄŸeri
    STRIDES = (1, 1)
    
    # ------------------------------ EÄžÄ°TÄ°M AYARLARI ---------------------------
    # Batch size
    BATCH_SIZE = 8
    
    # Epoch sayÄ±sÄ±
    EPOCHS = 20
    
    # Learning rate
    LEARNING_RATE = 0.001
    
    # Optimizer: "adam", "sgd", "rmsprop"
    OPTIMIZER = "adam"
    
    # Loss fonksiyonu: "mse", "mae", "binary_crossentropy", "ssim"
    LOSS_FUNCTION = "mse"
    
    # ------------------------------ KAYIT AYARLARI ----------------------------
    # Model kayÄ±t dizini (None = mevcut dizin)
    SAVE_DIR = None
    
    # Her epoch'ta checkpoint kaydet
    SAVE_CHECKPOINTS = True
    
    # KaÃ§ batch'te bir ara kayÄ±t yapÄ±lsÄ±n (0 = devre dÄ±ÅŸÄ±)
    PERIODIC_SAVE_STEPS = 0
    
    # Final model adÄ±
    FINAL_MODEL_NAME = "son_model.h5"
    
    # ------------------------------ VERÄ° PIPELINE AYARLARI --------------------
    # Paralel iÅŸlem sayÄ±sÄ± (None = AUTOTUNE)
    NUM_PARALLEL_CALLS = None
    
    # Prefetch buffer boyutu (None = AUTOTUNE)
    PREFETCH_BUFFER = None
    
    # Dosya doÄŸrulama modu:
    # "none": DoÄŸrulama yapma (en hÄ±zlÄ±, ignore_errors ile hatalar atlanÄ±r)
    # "quick": Sadece dosya boyutu kontrolÃ¼ (hÄ±zlÄ±)
    # "cached": Ä°lk sefer doÄŸrula, sonucu cache'le (400k dosya iÃ§in Ã¶nerilen)
    # "full": Her seferinde tam doÄŸrulama (yavaÅŸ)
    VALIDATE_FILES = "cached"
    
    # Cache dosyasÄ± adÄ± (VALIDATE_FILES="cached" iÃ§in)
    VALIDATION_CACHE_FILE = "valid_files_cache.json"
    
    # ------------------------------ GELÄ°ÅžMÄ°Åž AYARLAR --------------------------
    # Early stopping (0 = devre dÄ±ÅŸÄ±)
    EARLY_STOPPING_PATIENCE = 0
    
    # Learning rate azaltma (0 = devre dÄ±ÅŸÄ±)
    REDUCE_LR_PATIENCE = 0
    REDUCE_LR_FACTOR = 0.5
    
    # Dropout oranÄ± (bazÄ± modeller iÃ§in)
    DROPOUT_RATE = 0.3
    
    # L1 Regularization (gpt modeli iÃ§in)
    L1_REGULARIZATION = 1e-5


# ==============================================================================
#                              YARDIMCI FONKSÄ°YONLAR
# ==============================================================================

def get_timestamp():
    """Zaman damgasÄ± dÃ¶ndÃ¼rÃ¼r."""
    return datetime.datetime.strftime(datetime.datetime.now(), '%d_%m_%Y__%H_%M')


def get_channels():
    """Renk moduna gÃ¶re kanal sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
    if Config.COLOR_MODE == "rgb":
        return 3
    return 1


def get_input_shape(for_inference=False):
    """Model giriÅŸ boyutlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        for_inference: True ise dinamik boyut dÃ¶ndÃ¼rÃ¼r (None, None, channels)
    """
    if for_inference and Config.DYNAMIC_INPUT_FOR_INFERENCE:
        return (None, None, get_channels())
    return (Config.IMAGE_SIZE, Config.IMAGE_SIZE, get_channels())


# ==============================================================================
#                              LOSS FONKSÄ°YONLARI
# ==============================================================================

def ssim_loss(y_true, y_pred):
    """SSIM tabanlÄ± kayÄ±p fonksiyonu."""
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))


def get_loss_function():
    """YapÄ±landÄ±rmaya gÃ¶re kayÄ±p fonksiyonunu dÃ¶ndÃ¼rÃ¼r."""
    if Config.LOSS_FUNCTION == "ssim":
        return ssim_loss
    elif Config.LOSS_FUNCTION == "mse":
        return "mse"
    elif Config.LOSS_FUNCTION == "mae":
        return "mae"
    elif Config.LOSS_FUNCTION == "binary_crossentropy":
        return "binary_crossentropy"
    else:
        return Config.LOSS_FUNCTION


# ==============================================================================
#                              CALLBACK SINIFI
# ==============================================================================

class PeriodicSave(tf.keras.callbacks.Callback):
    """Belirli aralÄ±klarla model kaydeden callback."""
    
    def __init__(self, save_every=1000, model_name_prefix="model"):
        self.save_every = save_every
        self.model_name_prefix = model_name_prefix
        super(PeriodicSave, self).__init__()

    def on_train_batch_end(self, batch, logs=None):
        if self.save_every > 0 and batch % self.save_every == 0 and batch > 0:
            save_path = f'{self.model_name_prefix}_step_{batch}.h5'
            self.model.save(save_path)
            print(f"\n[PeriodicSave] Model kaydedildi: {save_path}")

    def on_epoch_end(self, epoch, logs=None):
        save_path = f'{self.model_name_prefix}_epoch_{epoch}.h5'
        self.model.save(save_path)


# ==============================================================================
#                              VERÄ° YÃœKLEME
# ==============================================================================

def get_random_size():
    """Multi-scale eÄŸitim iÃ§in rastgele boyut seÃ§er."""
    sizes = Config.MULTI_SCALE_SIZES
    idx = tf.random.uniform([], 0, len(sizes), dtype=tf.int32)
    return tf.gather(sizes, idx)


def load_and_preprocess(image_path):
    """GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kler ve Ã¶n iÅŸler."""
    channels = get_channels()
    use_equalize = Config.COLOR_MODE == "grayscale_with_equalize"
    
    # DosyayÄ± oku ve decode et
    img_raw = tf.io.read_file(image_path)
    img = tf.image.decode_image(img_raw, channels=channels)
    
    # Veri tipini float32'ye Ã§evir
    img = tf.cast(img, tf.float32)
    
    # BoyutlarÄ± al
    shape = tf.shape(img)
    height = shape[0]
    width = shape[1] // 2  # Girdi ve etiket yan yana
    
    # Girdi ve etiketi ayÄ±r
    input_img = tf.slice(img, [0, 0, 0], [height, width, channels])
    label_img = tf.slice(img, [0, width, 0], [height, width, channels])
    
    # Histogram eÅŸitleme (sadece grayscale_with_equalize modunda)
    if use_equalize and TFA_AVAILABLE:
        input_img = tfa.image.equalize(input_img)
    
    # BoyutlandÄ±rma
    target_size = Config.IMAGE_SIZE
    input_img = tf.image.resize(input_img, [target_size, target_size], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    label_img = tf.image.resize(label_img, [target_size, target_size], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
    # Normalizasyon (-1 ile 1 arasÄ±)
    input_img = (input_img - 127.5) / 127.5
    label_img = (label_img - 127.5) / 127.5
    
    return (input_img, label_img)


def load_and_preprocess_multiscale(image_path):
    """Multi-scale eÄŸitim iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ rastgele boyutta yÃ¼kler."""
    channels = get_channels()
    use_equalize = Config.COLOR_MODE == "grayscale_with_equalize"
    
    # DosyayÄ± oku ve decode et
    img_raw = tf.io.read_file(image_path)
    img = tf.image.decode_image(img_raw, channels=channels)
    img = tf.cast(img, tf.float32)
    
    # BoyutlarÄ± al
    shape = tf.shape(img)
    height = shape[0]
    width = shape[1] // 2
    
    # Girdi ve etiketi ayÄ±r
    input_img = tf.slice(img, [0, 0, 0], [height, width, channels])
    label_img = tf.slice(img, [0, width, 0], [height, width, channels])
    
    # Histogram eÅŸitleme
    if use_equalize and TFA_AVAILABLE:
        input_img = tfa.image.equalize(input_img)
    
    # Rastgele boyut seÃ§
    target_size = get_random_size()
    input_img = tf.image.resize(input_img, [target_size, target_size], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    label_img = tf.image.resize(label_img, [target_size, target_size], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
    # Normalizasyon
    input_img = (input_img - 127.5) / 127.5
    label_img = (label_img - 127.5) / 127.5
    
    return (input_img, label_img)


import json
import hashlib


def get_cache_path():
    """Cache dosyasÄ±nÄ±n tam yolunu dÃ¶ndÃ¼rÃ¼r."""
    cache_dir = Config.DATA_DIR
    return os.path.join(cache_dir, Config.VALIDATION_CACHE_FILE)


def compute_dataset_hash(image_paths):
    """Veri setinin hash'ini hesaplar (dosya listesi + toplam sayÄ±)."""
    # Sadece dosya adlarÄ±nÄ± ve toplam sayÄ±sÄ±nÄ± kullan (hÄ±zlÄ±)
    content = f"{len(image_paths)}:{sorted([os.path.basename(p) for p in image_paths[:100]])}"
    return hashlib.md5(content.encode()).hexdigest()


def load_validation_cache():
    """Cache dosyasÄ±nÄ± yÃ¼kler."""
    cache_path = get_cache_path()
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return None


def save_validation_cache(valid_files, dataset_hash):
    """DoÄŸrulama sonuÃ§larÄ±nÄ± cache'e kaydeder."""
    cache_path = get_cache_path()
    cache_data = {
        "hash": dataset_hash,
        "valid_files": valid_files,
        "count": len(valid_files),
        "timestamp": datetime.datetime.now().isoformat()
    }
    try:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f)
        print(f"âœ… DoÄŸrulama sonuÃ§larÄ± cache'lendi: {cache_path}")
    except Exception as e:
        print(f"âš ï¸ Cache kaydedilemedi: {e}")


def validate_quick(image_paths):
    """HÄ±zlÄ± doÄŸrulama - sadece dosya boyutu kontrolÃ¼."""
    valid = []
    invalid_count = 0
    
    for path in image_paths:
        try:
            if os.path.getsize(path) > 0:
                valid.append(path)
            else:
                invalid_count += 1
        except:
            invalid_count += 1
    
    if invalid_count > 0:
        print(f"âš ï¸ {invalid_count} boÅŸ/eriÅŸilemeyen dosya atlandÄ±")
    
    return valid


def validate_full(image_paths):
    """Tam doÄŸrulama - header kontrolÃ¼ dahil."""
    valid_paths = []
    invalid_count = 0
    total = len(image_paths)
    
    print("Tam doÄŸrulama yapÄ±lÄ±yor...")
    
    for i, path in enumerate(image_paths):
        # Progress her 10000 dosyada bir gÃ¶ster
        if i > 0 and i % 10000 == 0:
            print(f"  Ä°ÅŸleniyor: {i}/{total} ({i*100//total}%)")
        
        try:
            file_size = os.path.getsize(path)
            if file_size < 100:  # 100 byte'tan kÃ¼Ã§Ã¼k dosyalar ÅŸÃ¼pheli
                invalid_count += 1
                continue
            valid_paths.append(path)
        except:
            invalid_count += 1
    
    if invalid_count > 0:
        print(f"âš ï¸ {invalid_count} bozuk/boÅŸ dosya atlandÄ±")
    
    return valid_paths


def get_validated_paths(all_image_paths):
    """DoÄŸrulama moduna gÃ¶re geÃ§erli dosyalarÄ± dÃ¶ndÃ¼rÃ¼r."""
    mode = Config.VALIDATE_FILES.lower()
    
    if mode == "none":
        print("ðŸ“Œ Dosya doÄŸrulama: DEVRE DIÅžI (ignore_errors aktif)")
        return all_image_paths
    
    elif mode == "quick":
        print("ðŸ“Œ Dosya doÄŸrulama: HIZLI (sadece boyut kontrolÃ¼)")
        return validate_quick(all_image_paths)
    
    elif mode == "cached":
        print("ðŸ“Œ Dosya doÄŸrulama: CACHE MODUNDA")
        cache = load_validation_cache()
        dataset_hash = compute_dataset_hash(all_image_paths)
        
        if cache and cache.get("hash") == dataset_hash:
            print(f"âœ… Cache'den yÃ¼klendi: {cache['count']} geÃ§erli dosya")
            # Cache'deki dosyalarÄ±n hala var olduÄŸunu kontrol et
            valid_from_cache = [p for p in cache["valid_files"] if os.path.exists(p)]
            if len(valid_from_cache) == cache['count']:
                return valid_from_cache
            print("âš ï¸ BazÄ± dosyalar silinmiÅŸ, yeniden doÄŸrulanÄ±yor...")
        
        # Cache yoksa veya geÃ§ersizse, hÄ±zlÄ± doÄŸrulama yap ve cache'le
        print("ðŸ”„ Ä°lk kez doÄŸrulama yapÄ±lÄ±yor (bu sadece bir kez olacak)...")
        valid_paths = validate_quick(all_image_paths)
        save_validation_cache(valid_paths, dataset_hash)
        return valid_paths
    
    elif mode == "full":
        print("ðŸ“Œ Dosya doÄŸrulama: TAM (her dosya kontrol ediliyor)")
        return validate_full(all_image_paths)
    
    else:
        print(f"âš ï¸ Bilinmeyen doÄŸrulama modu: {mode}, 'none' kullanÄ±lÄ±yor")
        return all_image_paths


def create_datasets():
    """EÄŸitim ve doÄŸrulama veri setlerini oluÅŸturur."""
    # GÃ¶rÃ¼ntÃ¼ yollarÄ±nÄ± al
    all_image_paths = [
        os.path.join(Config.DATA_DIR, fname) 
        for fname in os.listdir(Config.DATA_DIR)
        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))
    ]
    
    if len(all_image_paths) == 0:
        raise ValueError(f"Veri dizininde gÃ¶rÃ¼ntÃ¼ bulunamadÄ±: {Config.DATA_DIR}")
    
    print(f"Toplam dosya sayÄ±sÄ±: {len(all_image_paths)}")
    
    # DoÄŸrulama moduna gÃ¶re filtreleme
    all_image_paths = get_validated_paths(all_image_paths)
    
    if len(all_image_paths) == 0:
        raise ValueError("HiÃ§ geÃ§erli gÃ¶rÃ¼ntÃ¼ dosyasÄ± bulunamadÄ±!")
    
    # Random seed ayarla
    np.random.seed(Config.RANDOM_SEED)
    
    # GÃ¶rÃ¼ntÃ¼ yollarÄ±nÄ± karÄ±ÅŸtÄ±r
    np.random.shuffle(all_image_paths)
    
    # EÄŸitim ve doÄŸrulama setlerini ayÄ±r
    split_at = int(len(all_image_paths) * Config.TRAIN_SPLIT)
    train_paths = all_image_paths[:split_at]
    val_paths = all_image_paths[split_at:]
    
    print(f"EÄŸitim seti: {len(train_paths)} gÃ¶rÃ¼ntÃ¼")
    print(f"DoÄŸrulama seti: {len(val_paths)} gÃ¶rÃ¼ntÃ¼")
    
    # Multi-scale eÄŸitim bilgisi
    if Config.MULTI_SCALE_TRAINING:
        print(f"Multi-scale eÄŸitim aktif. Boyutlar: {Config.MULTI_SCALE_SIZES}")
    
    # Paralel iÅŸlem ayarlarÄ±
    parallel_calls = Config.NUM_PARALLEL_CALLS
    if parallel_calls is None:
        parallel_calls = tf.data.experimental.AUTOTUNE
    
    prefetch_buffer = Config.PREFETCH_BUFFER
    if prefetch_buffer is None:
        prefetch_buffer = tf.data.experimental.AUTOTUNE
    
    # Preprocessing fonksiyonunu seÃ§
    if Config.MULTI_SCALE_TRAINING:
        # Multi-scale: her batch farklÄ± boyutta, batch_size=1 olmalÄ±
        preprocess_fn = load_and_preprocess_multiscale
        batch_size = 1  # Multi-scale'de batch=1 zorunlu (farklÄ± boyutlar)
        print("UYARI: Multi-scale modunda batch_size=1 kullanÄ±lÄ±yor.")
    else:
        preprocess_fn = load_and_preprocess
        batch_size = Config.BATCH_SIZE
    
    # Dataset oluÅŸtur - ignore_errors ile bozuk dosyalarÄ± atla
    train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)
    train_dataset = train_dataset.map(preprocess_fn, num_parallel_calls=parallel_calls)
    train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())  # HatalarÄ± atla
    train_dataset = train_dataset.batch(batch_size).prefetch(buffer_size=prefetch_buffer)
    
    val_dataset = tf.data.Dataset.from_tensor_slices(val_paths)
    val_dataset = val_dataset.map(load_and_preprocess, num_parallel_calls=parallel_calls)
    val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())  # HatalarÄ± atla
    val_dataset = val_dataset.batch(Config.BATCH_SIZE).prefetch(buffer_size=prefetch_buffer)
    
    return train_dataset, val_dataset


# ==============================================================================
#                              MODEL MÄ°MARÄ°LERÄ°
# ==============================================================================

def create_autoencoder_model(input_shape):
    """Standart autoencoder modeli."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    strides = Config.STRIDES
    activation_func = Config.ACTIVATION_FUNC
    
    input_layer = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(filter_count, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(input_layer)
    x = Conv2D(filter_count * 2, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2D(filter_count * 4, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    # Decoder
    x = Conv2DTranspose(filter_count * 4, kernel_size=kernel_size, strides=strides,
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2DTranspose(filter_count * 2, kernel_size=kernel_size, strides=strides,
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2DTranspose(filter_count, kernel_size=kernel_size, strides=strides,
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    output_layer = Conv2D(channels, kernel_size=kernel_size, strides=(1, 1),
                          activation=activation_func, padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_autoencoder_model_backup(input_shape):
    """Backup autoencoder modeli (alternatif mimari)."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    strides = Config.STRIDES
    activation_func = Config.ACTIVATION_FUNC
    
    input_layer = Input(shape=input_shape)
    
    x = Conv2D(filter_count, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(input_layer)
    x = Conv2D(filter_count * 2, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2D(filter_count * 4, kernel_size=(3, 3), strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2D(filter_count * 8, kernel_size=(3, 3), strides=(2, 2),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    x = Conv2DTranspose(filter_count * 4, kernel_size=(3, 3), strides=(2, 2),
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2DTranspose(filter_count * 2, kernel_size=kernel_size, strides=strides,
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    output_layer = Conv2DTranspose(channels, kernel_size=kernel_size, strides=strides,
                                   activation=activation_func, padding='same', kernel_initializer='he_normal')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_upsampled_autoencoder(input_shape):
    """UpSampling tabanlÄ± autoencoder."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    strides = Config.STRIDES
    
    input_layer = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(filter_count, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(input_layer)
    x = Conv2D(filter_count // 2, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2D(filter_count // 4, kernel_size=kernel_size, strides=strides,
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2D(filter_count // 8, kernel_size=(2, 2), strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    # Decoder
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(filter_count // 4, kernel_size=kernel_size, strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(filter_count // 2, kernel_size=kernel_size, strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    x = UpSampling2D(size=(2, 2))(x)
    output_layer = Conv2D(channels, kernel_size=kernel_size, strides=(1, 1),
                          activation='elu', padding='same', kernel_initializer='he_normal')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_advanced_autoencoder(input_shape):
    """GeliÅŸmiÅŸ autoencoder (MaxPooling + Dropout)."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    strides = Config.STRIDES
    activation_func = Config.ACTIVATION_FUNC
    dropout_rate = Config.DROPOUT_RATE
    
    input_layer = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(filter_count // 2, kernel_size=kernel_size, strides=strides,
               activation=activation_func, padding='same')(input_layer)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(dropout_rate)(x)
    
    x = Conv2D(filter_count, kernel_size=kernel_size, strides=strides,
               activation=activation_func, padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    
    x = Conv2D(filter_count * 2, kernel_size=kernel_size, strides=strides,
               activation=activation_func, padding='same')(x)
    
    # Decoder
    x = Conv2DTranspose(filter_count * 2, kernel_size=kernel_size, strides=strides,
                        activation=activation_func, padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(dropout_rate)(x)
    
    x = Conv2DTranspose(filter_count, kernel_size=kernel_size, strides=strides,
                        activation=activation_func, padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(dropout_rate)(x)
    
    x = Conv2DTranspose(filter_count // 2, kernel_size=kernel_size, strides=(1, 1),
                        activation=activation_func, padding='same')(x)
    
    output_layer = Conv2DTranspose(channels, kernel_size=kernel_size, strides=strides,
                                   activation=activation_func, padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_gpt_autoencoder(input_shape):
    """GPT tarzÄ± autoencoder (L1 regularization ile)."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    l1_reg = Config.L1_REGULARIZATION
    
    input_layer = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(filter_count / 2, kernel_size, activation='elu', padding='same',
               activity_regularizer=regularizers.l1(l1_reg))(input_layer)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(0.4)(x)
    
    x = Conv2D(filter_count, kernel_size, activation='elu', padding='same',
               activity_regularizer=regularizers.l1(l1_reg))(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(0.4)(x)
    
    x = Conv2D(filter_count * 2, kernel_size, activation='elu', padding='same',
               activity_regularizer=regularizers.l1(l1_reg))(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(0.4)(x)
    
    # Decoder
    x = Conv2DTranspose(filter_count * 2, kernel_size, activation='elu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(0.4)(x)
    
    x = Conv2DTranspose(filter_count, kernel_size, activation='elu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(0.4)(x)
    
    x = Conv2DTranspose(filter_count / 2, kernel_size, activation='elu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(0.4)(x)
    
    output_layer = Conv2DTranspose(channels, kernel_size, activation='sigmoid', padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_gpt_autoencoder_no_reg(input_shape):
    """GPT tarzÄ± autoencoder (regularization olmadan)."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    
    input_layer = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(filter_count, kernel_size, activation='elu', padding='same')(input_layer)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(0.4)(x)
    
    x = Conv2D(filter_count * 2, kernel_size, activation='elu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Dropout(0.4)(x)
    
    # Decoder
    x = Conv2DTranspose(filter_count * 2, kernel_size, activation='elu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(0.4)(x)
    
    x = Conv2DTranspose(filter_count, kernel_size, activation='elu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Dropout(0.4)(x)
    
    output_layer = Conv2DTranspose(channels, kernel_size, activation='sigmoid', padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_deneysel_model(input_shape):
    """Deneysel model (basit ve hÄ±zlÄ±)."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    activation_func = Config.ACTIVATION_FUNC
    
    input_layer = Input(shape=input_shape)
    
    x = Conv2D(filter_count * 16, kernel_size=(5, 5), strides=(2, 2),
               activation='relu', padding='same', kernel_initializer='he_normal')(input_layer)
    x = Conv2D(filter_count * 8, kernel_size=kernel_size, strides=(1, 1),
               activation='relu', padding='same', kernel_initializer='he_normal')(x)
    
    x = Conv2DTranspose(filter_count * 4, kernel_size=kernel_size, strides=(1, 1),
                        activation='relu', padding='same', kernel_initializer='he_normal')(x)
    x = Conv2DTranspose(filter_count * 2, kernel_size=(5, 5), strides=(2, 2),
                        activation='relu', padding='same', kernel_initializer='he_normal')(x)
    
    output_layer = Conv2D(channels, kernel_size=kernel_size, strides=(1, 1),
                          activation=activation_func, padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def create_classic_model(input_shape):
    """Klasik autoencoder modeli."""
    channels = input_shape[-1]
    filter_count = Config.FILTER_COUNT
    kernel_size = Config.KERNEL_SIZE
    activation_func = Config.ACTIVATION_FUNC
    dropout_rate = Config.DROPOUT_RATE
    
    input_layer = Input(shape=input_shape)
    
    x = Conv2D(filter_count * 16, kernel_size=kernel_size, strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(input_layer)
    x = Dropout(dropout_rate)(x)
    x = Conv2D(filter_count * 8, kernel_size=kernel_size, strides=(1, 1),
               activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Dropout(dropout_rate)(x)
    
    x = Conv2DTranspose(filter_count * 8, kernel_size=kernel_size, strides=(1, 1),
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Dropout(dropout_rate)(x)
    x = Conv2DTranspose(filter_count * 16, kernel_size=kernel_size, strides=(1, 1),
                        activation='elu', padding='same', kernel_initializer='he_normal')(x)
    x = Dropout(dropout_rate)(x)
    
    output_layer = Conv2D(channels, kernel_size=kernel_size, strides=(1, 1),
                          activation=activation_func, padding='same')(x)
    
    return Model(inputs=input_layer, outputs=output_layer)


def get_model(input_shape):
    """YapÄ±landÄ±rmaya gÃ¶re model oluÅŸturur veya yÃ¼kler."""
    
    # Ã–nceden eÄŸitilmiÅŸ model varsa yÃ¼kle
    if Config.PRETRAINED_MODEL is not None:
        if os.path.exists(Config.PRETRAINED_MODEL):
            print(f"Ã–nceden eÄŸitilmiÅŸ model yÃ¼kleniyor: {Config.PRETRAINED_MODEL}")
            return load_model(Config.PRETRAINED_MODEL, custom_objects={'ssim_loss': ssim_loss})
        else:
            print(f"UYARI: Model dosyasÄ± bulunamadÄ±: {Config.PRETRAINED_MODEL}")
            print("SÄ±fÄ±rdan model oluÅŸturuluyor...")
    
    # Model tipine gÃ¶re oluÅŸtur
    model_builders = {
        "autoencoder": create_autoencoder_model,
        "autoencoder_backup": create_autoencoder_model_backup,
        "upsampled": create_upsampled_autoencoder,
        "advanced": create_advanced_autoencoder,
        "gpt": create_gpt_autoencoder,
        "gpt_no_reg": create_gpt_autoencoder_no_reg,
        "deneysel": create_deneysel_model,
        "classic": create_classic_model,
    }
    
    model_type = Config.MODEL_TYPE.lower()
    if model_type not in model_builders:
        raise ValueError(f"Bilinmeyen model tipi: {Config.MODEL_TYPE}. "
                        f"GeÃ§erli tipler: {list(model_builders.keys())}")
    
    print(f"Model oluÅŸturuluyor: {Config.MODEL_TYPE}")
    return model_builders[model_type](input_shape)


# ==============================================================================
#                              OPTIMIZER
# ==============================================================================

def get_optimizer():
    """YapÄ±landÄ±rmaya gÃ¶re optimizer dÃ¶ndÃ¼rÃ¼r."""
    if Config.OPTIMIZER.lower() == "adam":
        return tf.keras.optimizers.Adam(learning_rate=Config.LEARNING_RATE)
    elif Config.OPTIMIZER.lower() == "sgd":
        return tf.keras.optimizers.SGD(learning_rate=Config.LEARNING_RATE)
    elif Config.OPTIMIZER.lower() == "rmsprop":
        return tf.keras.optimizers.RMSprop(learning_rate=Config.LEARNING_RATE)
    else:
        return Config.OPTIMIZER


# ==============================================================================
#                              CALLBACKS
# ==============================================================================

def get_callbacks():
    """TÃ¼m callback'leri oluÅŸturur."""
    callbacks = []
    timestamp = get_timestamp()
    
    # Checkpoint callback
    if Config.SAVE_CHECKPOINTS:
        checkpoint_path = f'_{timestamp}_model_f{Config.FILTER_COUNT}_k{Config.KERNEL_SIZE[0]}_epoch_{{epoch:05d}}_{Config.ACTIVATION_FUNC}_{Config.STRIDES}_.h5'
        if Config.SAVE_DIR:
            checkpoint_path = os.path.join(Config.SAVE_DIR, checkpoint_path)
        
        checkpoint = ModelCheckpoint(
            checkpoint_path,
            save_freq='epoch',
            save_best_only=False,
            verbose=1
        )
        callbacks.append(checkpoint)
    
    # Periodic save callback
    if Config.PERIODIC_SAVE_STEPS > 0:
        model_prefix = f'_{timestamp}_{Config.FILTER_COUNT}_{Config.KERNEL_SIZE[0]}_{Config.STRIDES}'
        if Config.SAVE_DIR:
            model_prefix = os.path.join(Config.SAVE_DIR, model_prefix)
        
        periodic_save = PeriodicSave(
            save_every=Config.PERIODIC_SAVE_STEPS,
            model_name_prefix=model_prefix
        )
        callbacks.append(periodic_save)
    
    # Early stopping
    if Config.EARLY_STOPPING_PATIENCE > 0:
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=Config.EARLY_STOPPING_PATIENCE,
            restore_best_weights=True,
            verbose=1
        )
        callbacks.append(early_stopping)
    
    # Learning rate reduction
    if Config.REDUCE_LR_PATIENCE > 0:
        reduce_lr = ReduceLROnPlateau(
            monitor='val_loss',
            factor=Config.REDUCE_LR_FACTOR,
            patience=Config.REDUCE_LR_PATIENCE,
            min_lr=1e-7,
            verbose=1
        )
        callbacks.append(reduce_lr)
    
    return callbacks


# ==============================================================================
#                              ANA FONKSÄ°YON
# ==============================================================================

def print_config():
    """Mevcut yapÄ±landÄ±rmayÄ± yazdÄ±rÄ±r."""
    print("\n" + "=" * 60)
    print("                    YAPILANDIRMA")
    print("=" * 60)
    print(f"  Veri Dizini:        {Config.DATA_DIR}")
    print(f"  Renk Modu:          {Config.COLOR_MODE}")
    print(f"  GÃ¶rÃ¼ntÃ¼ Boyutu:     {Config.IMAGE_SIZE}x{Config.IMAGE_SIZE}")
    print(f"  Model Tipi:         {Config.MODEL_TYPE}")
    print(f"  Ã–nceden EÄŸitilmiÅŸ:  {Config.PRETRAINED_MODEL or 'Yok'}")
    print(f"  Aktivasyon:         {Config.ACTIVATION_FUNC}")
    print(f"  Filtre SayÄ±sÄ±:      {Config.FILTER_COUNT}")
    print(f"  Kernel Boyutu:      {Config.KERNEL_SIZE}")
    print(f"  Stride:             {Config.STRIDES}")
    print(f"  Batch Size:         {Config.BATCH_SIZE}")
    print(f"  Epochs:             {Config.EPOCHS}")
    print(f"  Learning Rate:      {Config.LEARNING_RATE}")
    print(f"  Optimizer:          {Config.OPTIMIZER}")
    print(f"  Loss:               {Config.LOSS_FUNCTION}")
    print(f"  Train/Val Split:    {Config.TRAIN_SPLIT}/{1-Config.TRAIN_SPLIT}")
    print(f"  Random Seed:        {Config.RANDOM_SEED}")
    print("=" * 60 + "\n")


def main():
    """Ana eÄŸitim fonksiyonu."""
    
    # YapÄ±landÄ±rmayÄ± yazdÄ±r
    print_config()
    
    # KayÄ±t dizinini oluÅŸtur
    if Config.SAVE_DIR and not os.path.exists(Config.SAVE_DIR):
        os.makedirs(Config.SAVE_DIR)
        print(f"KayÄ±t dizini oluÅŸturuldu: {Config.SAVE_DIR}")
    
    # Veri setlerini oluÅŸtur
    print("Veri setleri oluÅŸturuluyor...")
    train_dataset, val_dataset = create_datasets()
    
    # Model oluÅŸtur
    input_shape = get_input_shape()
    print(f"GiriÅŸ boyutu: {input_shape}")
    
    model = get_model(input_shape)
    
    # Model derle
    optimizer = get_optimizer()
    loss_fn = get_loss_function()
    
    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])
    
    # Modelin Ã¶zetini yazdÄ±r
    model.summary()
    
    # Callback'leri al
    callbacks = get_callbacks()
    
    # EÄŸitimi baÅŸlat
    print("\n" + "=" * 60)
    print("                    EÄžÄ°TÄ°M BAÅžLIYOR")
    print("=" * 60 + "\n")
    
    history = model.fit(
        train_dataset,
        validation_data=val_dataset,
        epochs=Config.EPOCHS,
        callbacks=callbacks
    )
    
    # Final modeli kaydet
    final_model_path = Config.FINAL_MODEL_NAME
    if Config.SAVE_DIR:
        final_model_path = os.path.join(Config.SAVE_DIR, final_model_path)
    
    model.save(final_model_path)
    print(f"\nFinal model kaydedildi: {final_model_path}")
    
    print("\n" + "=" * 60)
    print("                    EÄžÄ°TÄ°M TAMAMLANDI")
    print("=" * 60 + "\n")
    
    return model, history


if __name__ == "__main__":
    main()
